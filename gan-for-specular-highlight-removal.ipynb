{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from tensorflow.keras.models import Sequential, Model\nfrom keras.layers import Input, Dense, Reshape, Flatten, Dropout, Concatenate, MaxPooling2D\nfrom keras.layers import BatchNormalization, Activation, ZeroPadding2D, Add\nfrom keras.layers.advanced_activations import PReLU, LeakyReLU\nfrom keras.layers.convolutional import UpSampling2D, Conv2D\nfrom keras.applications import VGG19\nfrom keras.models import Sequential, Model\nimport matplotlib.pyplot as plt\nfrom keras.optimizers import Adam\n\nclass GAN:\n    def __init__(self, x, y):\n        print(x.shape[0])\n        self.input_shape = (x[0].shape)\n        self.x = x\n        self.y = y\n        # Number of residual blocks in the generator\n        self.n_residual_blocks = 16\n        \n        optimizer = Adam(0.0002, 0.5)\n        \n#         patch = int(self.x.shape[0] / 2**4)\n        self.disc_patch = (8,8,1)\n        \n        self.vgg = self.build_vgg()\n        self.vgg.trainable = False\n        self.vgg.compile(loss='mse',\n            optimizer=optimizer,\n            metrics=['accuracy'])\n        \n        # build and comple discriminator\n        self.discriminator = self._get_discriminator()\n        self.discriminator.compile(loss='mse',\n            optimizer=optimizer,\n            metrics=['accuracy'])\n        \n        # build generator\n        self.generator = self._get_generator()\n        \n        img_sh = Input(shape=self.input_shape)\n        img_d = Input(shape=self.input_shape)\n        \n        fake_d = self.generator(img_sh)\n        \n        # Extract image features of the generated img\n        fake_features = self.vgg(fake_d)\n        \n         # For the combined model we will only train the generator\n        self.discriminator.trainable = False\n        \n        validity = self.discriminator(fake_d)\n        \n        self.gan = Model([img_sh, img_d], [validity, fake_features])\n        self.gan.compile(loss=['binary_crossentropy', 'mse'],\n                              loss_weights=[1e-3, 1],\n                              optimizer=optimizer)\n    def build_vgg(self):\n        \"\"\"\n        Builds a pre-trained VGG19 model that outputs image features extracted at the\n        third block of the model\n        \"\"\"\n        vgg = VGG19(weights=\"imagenet\", include_top = False,input_shape = self.input_shape)\n        # Set outputs to outputs of last conv. layer in block 3\n        # See architecture at: https://github.com/keras-team/keras/blob/master/keras/applications/vgg19.py\n        model = Model(inputs=vgg.inputs, outputs=vgg.layers[9].output)\n\n        return model\n    \n    def _get_generator(self):\n        \n        def create_block(input, chs): ## Convolution block of 2 layers for conv autoencoder\n            x = input\n            for i in range(2):\n                x = Conv2D(chs, 3, padding=\"same\")(x)\n                x = Activation(\"relu\")(x)\n                x = BatchNormalization()(x)\n            return x\n        \n        input = Input(self.input_shape)\n    \n        # Encoder\n        block1 = create_block(input, 32)\n        x = MaxPooling2D(2)(block1)\n        block2 = create_block(x, 64)\n        x = MaxPooling2D(2)(block2)\n\n\n        #Middle\n        middle = create_block(x, 128)\n    #     middle = AdaIN()(encoder.outputs)\n\n        # Decoder\n        up1 = UpSampling2D((2,2))(middle)\n        block3 = create_block(up1, 64)\n        #up1 = UpSampling2D((2,2))(block3)\n        up2 = UpSampling2D((2,2))(block3)\n        block4 = create_block(up2, 32)\n        #up2 = UpSampling2D((2,2))(block4)\n\n        # output\n        x = Conv2D(3, 1)(up2)\n        output = Activation(\"sigmoid\")(x)\n\n        return Model(input, output)\n    \n    def _get_discriminator(self):\n        def d_block(layer_input, filters=64, strides=1, bn=True):\n            \"\"\"Discriminator layer\"\"\"\n            d = Conv2D(filters, kernel_size=3, strides=strides, padding='same')(layer_input)\n            d = LeakyReLU(alpha=0.2)(d)\n            if bn:\n                d = BatchNormalization(momentum=0.8)(d)\n            return d\n\n        # Input img\n        d0 = Input(shape=self.input_shape)\n\n        d1 = d_block(d0, 64, bn=False)\n        d2 = d_block(d1, 64, strides=2)\n        d3 = d_block(d2, 64*2)\n        d4 = d_block(d3, 64*2, strides=2)\n        d5 = d_block(d4, 64*4)\n        d6 = d_block(d5, 64*4, strides=2)\n        d7 = d_block(d6, 64*8)\n        d8 = d_block(d7, 64*8, strides=2)\n\n        d9 = Dense(64*16)(d8)\n        d10 = LeakyReLU(alpha=0.2)(d9)\n        validity = Dense(1, activation='sigmoid')(d10)\n\n        return Model(d0, validity)\n        \n#     def _get_gan(self, generator, discriminator):\n#         discriminator.trainable = False\n        \n#         gan_input = Input(shape=self.input_shape)\n#         generated = generator(gan_input)\n#         output = discriminator(generated)\n#         gan = Model(inputs=gan_input, outputs=[generated,output])\n        \n#         gan.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n#         return gan\n    \n    def train(self, epochs, batch_size=128):\n        accuracy = 0.5\n        \n        for e in range(1, epochs+1):\n            print('-'*10, 'Epoch %s' % e, '-'*10)\n            \n            batch = np.random.randint(0, self.x.shape[0], size=batch_size)\n            image_noise_batch = self.x[batch]\n            image_batch = self.y[batch]\n            \n            generated = self.generator.predict(image_noise_batch)\n            X = np.concatenate([image_batch, generated])\n            \n            y_dis = np.zeros(2*batch_size)\n            y_dis[:batch_size] = 1\n            \n            self.discriminator.trainable = True\n            self.generator.trainable = False\n            \n            accuracy = 0.5\n            while accuracy < 0.9:\n                disc_loss, accuracy = self.discriminator.train_on_batch(X, y_dis)\n                print('Discriminator accuracy:', accuracy)\n                \n            y_gen = np.ones(batch_size)\n            self.discriminator.trainable = False\n            self.generator.trainable = True\n            gan_accuracy = 0\n            while gan_accuracy < 0.6:\n                gan_loss, gan_accuracy = self.gan.train_on_batch(image_noise_batch, y_gen)\n                print('GAN accuracy:', gan_accuracy)\n            \n            print('Discriminator loss:', disc_loss, \n                  'Discriminator accuracy:', accuracy,\n                  'GAN loss:', gan_loss,\n                  'GAN accuracy:', gan_accuracy)\n            \n            if e == 1 or e % 5 == 0:\n                self.plot_images(e)\n            \n    \n                \n    def train_new(self,epoch_num, batch_size=128):\n        \n        \n        for epoch in range(epoch_num):\n           \n             # ----------------------\n            #  Train Discriminator\n            # ----------------------\n\n            # [Batch Preparation]\n            batch = np.random.randint(0, self.x.shape[0], size=batch_size)\n            image_sh = np.array(self.x[batch])\n            image_d = np.array(self.y[batch])\n\n            # Generate fake inputs\n            fake_d = self.generator.predict(image_sh)\n        \n        \n            valid = np.ones((batch_size,) + self.disc_patch)\n            fake = np.zeros((batch_size,)+ self.disc_patch)\n           \n            d_loss_real = self.discriminator.train_on_batch(image_d, valid)\n            d_loss_fake = self.discriminator.train_on_batch(fake_d, fake)\n            d_loss = 0.5 * np.add(d_loss_fake, d_loss_real)\n\n        # ------------------\n        #  Train Generator\n        # ------------------\n\n\n            # The generators want the discriminators to label the generated images as real\n            valid = np.ones((batch_size,)+ self.disc_patch)\n\n            # Extract ground truth image features using pre-trained VGG19 model\n            image_features = self.vgg.predict(image_d)\n\n            # Train the generators\n            g_loss = self.gan.train_on_batch([image_sh, image_d], [valid, image_features])\n\n\n\n            # If at save interval => save generated image samples\n            if epoch % 50 == 0:\n                print('d_loss_real:', d_loss_real, \n                'd_loss_fake:', d_loss_fake,\n                'd_loss:', d_loss,\n                'GAN loss:', g_loss)\n                self.plot_images(epoch)\n            \n    def plot_images(self, epoch):\n        image_noise_batch = self.x[np.random.randint(0, self.x.shape[0], size=2)]\n        generated_images = self.generator.predict(image_noise_batch)\n        \n        fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(16,16))\n        \n        ax[0][0].imshow(image_noise_batch[0])\n        ax[0][1].imshow(generated_images[0])\n        ax[1][0].imshow(image_noise_batch[1])\n        ax[1][1].imshow(generated_images[1])\n        plt.show()\n\nimport numpy as np\nfrom keras.preprocessing.image import load_img\n\nimage_shape = 256\n\ndef load_reshape_img(fname):\n    img = load_img(fname,target_size=(image_shape,image_shape))\n    x_float = np.array(img).astype('float32') / 255.\n    x = im_crop(x_float)\n    return x\n\ndef im_crop(image):\n    im_cropped = image[12:140,72:200,]\n    return im_cropped\n\ndef generate_x():\n    MAIN_DIR = \"/kaggle/input/mayadatasetv2/input/train/train_x/x/\"\n    image_df = []\n    for idx in range(1,8):\n        for i in range(1,11):\n            for j in range(1,13):\n                IMAGE_PATH = \"Female_\"+str(idx)+\".\"+'{:02}'.format(j)+\"_scene\"+str(i)+\".jpg\"\n                im = load_reshape_img(MAIN_DIR+IMAGE_PATH)\n                image_df.append(im)\n    return np.array(image_df)\n\ndef generate_y():\n    MAIN_DIR = \"/kaggle/input/mayadatasetv2/input/train/train_y/y/\"\n    image_df = []\n    for idx in range(1,8):\n        for i in range(1,11):\n            for j in range(1,13):\n                IMAGE_PATH = \"Female_\"+str(idx)+\".\"+'{:02}'.format(j)+\"_scene\"+str(i)+\".jpg\"\n                im = load_reshape_img(MAIN_DIR+IMAGE_PATH)\n                image_df.append(im)\n    return np.array(image_df)\n\n\n\n\ngan = GAN(generate_x(), generate_y())\ngan.train_new(3000)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_reshape_img_real(fname):\n    img = load_img(fname,target_size=(128,128))\n    x_float = np.array(img).astype('float32') / 255.\n    return x_float\n\ndef generate_real_test():\n    #../input/real-specular/real_specular/Image-12.jpg\n    MAIN_DIR = \"../input/realspecularimages/real_specular_images/\"\n    image_df = []\n    for i in range(8):\n#         print(MAIN_DIR+\"Capture\"+str(i)+\".jpg\")\n        im = load_reshape_img_real( MAIN_DIR+\"Capture\"+str(i)+\".JPG\")\n        image_df.append(im)\n    return np.array(image_df)\n\n\nx = generate_real_test()\n\nfake_d = gan.generator.predict(x)\n\nfig, ax = plt.subplots(nrows=6, ncols=2, figsize=(16,16))\n        \nax[0][0].imshow(x[0])\nax[0][1].imshow(fake_d[0])\nax[1][0].imshow(x[1])\nax[1][1].imshow(fake_d[1])\nax[2][0].imshow(x[2])\nax[2][1].imshow(fake_d[2])\nax[3][0].imshow(x[3])\nax[3][1].imshow(fake_d[3])\nax[4][0].imshow(x[4])\nax[4][1].imshow(fake_d[4])\nax[5][0].imshow(x[5])\nax[5][1].imshow(fake_d[5])\n\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generate_test():\n    MAIN_x_DIR = \"../input/mayadatasetv2/input/test/test_x/x/\"\n    MAIN_y_DIR = \"../input/mayadatasetv2/input/test/test_y/y/\"\n    image_x_df = []\n    image_y_df = []\n    female_idx = [18, 18, 21, 22, 19, 22, 21, 19, 21, 20]\n    angle_idx = [6, 8, 6, 2, 8, 10, 8, 8, 11, 6]\n    scene = [4, 6, 6, 7, 2, 2, 1, 7, 9, 1]\n    for idx in range(1,11):\n        IMAGE_PATH = \"Female_\"+str(female_idx[idx-1])+\".\"+'{:02}'.format(angle_idx[idx-1])+\"_scene\"+str(scene[idx-1])+\".jpg\"\n        im_x = load_reshape_img(MAIN_x_DIR+IMAGE_PATH)\n        im_y = load_reshape_img(MAIN_y_DIR+IMAGE_PATH)\n        image_x_df.append(im_x)\n        image_y_df.append(im_y)\n    return np.array(image_x_df),np.array(image_y_df)\n\nx, y = generate_test()\nrecons = gan.generator.predict(x)\n\n\n# fig, ax = plt.subplots(nrows=10, ncols=2, figsize=(16,16))\n  \nfig, ax = plt.subplots(nrows=2, ncols=2, figsize=(16,16))\nax[0][0].imshow(x[0])\nax[0][1].imshow(recons[0])\nax[1][0].imshow(x[1])\nax[1][1].imshow(recons[1])\n\nfig, ax = plt.subplots(nrows=2, ncols=2, figsize=(16,16))\n\nax[0][0].imshow(x[2])\nax[0][1].imshow(recons[2])\nax[1][0].imshow(x[3])\nax[1][1].imshow(recons[3])\n\nfig, ax = plt.subplots(nrows=2, ncols=2, figsize=(16,16))\nax[0][0].imshow(x[4])\nax[0][1].imshow(recons[4])\nax[1][0].imshow(x[5])\nax[1][1].imshow(recons[5])\n\nfig, ax = plt.subplots(nrows=2, ncols=2, figsize=(16,16))\n\nax[0][0].imshow(x[6])\nax[0][1].imshow(recons[6])\nax[1][0].imshow(x[7])\nax[1][1].imshow(recons[7])\n\n\nfig, ax = plt.subplots(nrows=2, ncols=2, figsize=(16,16))\n\nax[0][0].imshow(x[8])\nax[0][1].imshow(recons[8])\nax[1][0].imshow(x[9])\nax[1][1].imshow(recons[9])\n\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}